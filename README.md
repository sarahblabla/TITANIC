# TITANIC

This project aims to predict passenger survival on the Titanic using **classification models**. By applying machine learning techniques, we explore how different factors influenced survival rates.  

## **Table of Contents**  
1. [Importing Libraries](#importing-libraries)  
2. [Reading Data](#reading-data)  
3. [Exploratory Data Analysis](#exploratory-data-analysis)  
4. [Feature Engineering](#feature-engineering)  
5. [Random Forest](#random-forest)  
6. [Gradient Boosting](#gradient-boosting)  
7. [Logistic Regression](#logistic-regression)  
8. [Combining 3 ML Algorithms](#combining-3-ml-algorithms)  
9. [Conclusion](#conclusion)  

## **1. Importing Libraries**  
We begin by importing essential Python libraries such as **Pandas, NumPy, Matplotlib, Seaborn**, and machine learning libraries from **Scikit-Learn**.  

## **2. Reading Data**  
The dataset is loaded and inspected to understand the structure and missing values.  

## **3. Exploratory Data Analysis**  
EDA is conducted to identify key patterns, relationships, and potential outliers in the dataset. Visualizations help in understanding the impact of factors like gender, ticket class, and family size on survival.  

## **4. Feature Engineering**  
- Handling missing values  
- Encoding categorical variables  
- Creating new features to improve model accuracy  

## **5. Random Forest**  
A **Random Forest Classifier** is implemented to leverage multiple decision trees for better predictive performance.  

## **6. Gradient Boosting**  
Gradient Boosting models like **XGBoost** or **LightGBM** are used to enhance predictions by sequentially improving weak models.  

## **7. Logistic Regression**  
A baseline **Logistic Regression** model is applied to understand the fundamental relationships between features and survival probability.  

## **8. Combining 3 ML Algorithms**  
To improve accuracy, we create an **ensemble model** that combines predictions from Random Forest, Gradient Boosting, and Logistic Regression.  

## **9. Conclusion**  
The final section summarizes key findings, model performance, and potential areas for further improvement.  
